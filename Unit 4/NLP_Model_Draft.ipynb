{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Model Draft",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "QiBGR79lGaVV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d4a704c0-f6b3-4135-c90f-b3ef8507550a"
      },
      "cell_type": "code",
      "source": [
        "#Basic imports \n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "#NLP imports \n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import spacy\n",
        "spacy.load('en')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Dimension Reduction \n",
        "from sklearn.decomposition import TruncatedSVD, PCA\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "#Model Imports \n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "#Time\n",
        "import time "
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LQ6vMEl0HrPW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://www.dropbox.com/s/d4ye48a67tth2ae/Reviews.csv?dl=1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "539YrJZ3JK7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "a4df11c7-35fc-46a1-a3aa-9c7e2e3d291d"
      },
      "cell_type": "code",
      "source": [
        "#drop uneccessary columns \n",
        "df.drop(['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time', 'Summary'],axis=1,inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Score                                               Text\n",
              "0      5  I have bought several of the Vitality canned d...\n",
              "1      1  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2      4  This is a confection that has been around a fe...\n",
              "3      2  If you are looking for the secret ingredient i...\n",
              "4      5  Great taffy at a great price.  There was a wid..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "153OctxzJ_2V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "da1c11f7-386d-4c0a-ff44-120f5bedca59"
      },
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 2 columns):\n",
            "Score    568454 non-null int64\n",
            "Text     568454 non-null object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 8.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EA2MTL7xKVTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "44beccb6-54a3-4ac7-bf1a-5a909dc1c0ce"
      },
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Score    0\n",
              "Text     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "N6W9jrbGKZYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "85e213cc-a7a2-40bb-fb99-ed0dc947d6ca"
      },
      "cell_type": "code",
      "source": [
        "df.Score.value_counts()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    363122\n",
              "4     80655\n",
              "1     52268\n",
              "3     42640\n",
              "2     29769\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "8SZT9dyPKwFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utility function to clean text.\n",
        "def text_cleaner(text):\n",
        "    \n",
        "    # Visual inspection shows spaCy does not recognize the double dash '--'.\n",
        "    \n",
        "    text = re.sub(r'--',' ',text)\n",
        "    \n",
        "    # Removes hyperlinks \n",
        "    text = re.sub(r'<a\\s+href=(?:\"([^\"]+)\"|\\'([^\\']+)\\').*?>(.*?)</a>',' ', text)\n",
        "    \n",
        "    # Get rid of extra whitespace.\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEYnv5jYM3aO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['Clean'] = df['Text'].apply(lambda x: text_cleaner(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m1fC-WEkN7au",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create training/test sets\n",
        "X = df.Clean\n",
        "y = df.Score\n",
        "\n",
        "#split out training/test data \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
        "\n",
        "#split training set again to test best params with reduce execution times \n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train,y_train, test_size=0.8, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rGKMveUQNUiV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a985d619-2144-44d8-fd76-6fd81c34af2e"
      },
      "cell_type": "code",
      "source": [
        "# Display the shape to make sure the length is the same.\n",
        "print(X_train2.shape)\n",
        "print(y_train2.shape)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90952,)\n",
            "(90952,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Kqcn3ndzQRAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e2ed3de1-149c-4c91-b76f-1fed776df714"
      },
      "cell_type": "code",
      "source": [
        "# Setting max features to 1000 will choose the 1000 with the highest count.\n",
        "vectorizer = CountVectorizer(max_features=1000)\n",
        "# Train the model and transform it\n",
        "X_train2_matrix = vectorizer.fit_transform(X_train2)\n",
        "\n",
        "X_train2_matrix"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<90952x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 3878310 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "metadata": {
        "id": "TGhN7mlyo32l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "27ee631f-7121-4e65-bbec-728eb09a0339"
      },
      "cell_type": "code",
      "source": [
        "# X_test\n",
        "X_test_matrix = vectorizer.transform(X_test)\n",
        "X_test_matrix"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<113691x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 4812344 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "metadata": {
        "id": "pGQ-cO-ep0xM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logisitc Regression Model"
      ]
    },
    {
      "metadata": {
        "id": "kVfYZdtPnGkV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "874d3781-2a9d-4ea3-c296-3657c2e40b88"
      },
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "param_dist = {'penalty':['l1','l2'],\n",
        "                'C':[1,100,1000]}\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "random_search = RandomizedSearchCV(LogisticRegression(class_weight = 'balanced',random_state=0, n_jobs= -1), param_distributions=param_dist, n_iter=5)\n",
        "#Fit the Data\n",
        "random_search.fit(X_train2_matrix, y_train2)\n",
        "print(random_search.score(X_test_matrix, y_test))\n",
        "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6869057357222648\n",
            "-- Execution time: 260.53825545310974 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4fTOqYS5q3g-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b4bfd108-7ae0-4dc9-a6ff-9c2b9e8cfb47"
      },
      "cell_type": "code",
      "source": [
        "random_search.best_params_"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'penalty': 'l1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "metadata": {
        "id": "g-ZTXObHq-d7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "077713a3-6d5f-45a0-e4e6-e3a289973ee0"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, random_search.predict(X_test_matrix)))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.52      0.65      0.57     10267\n",
            "           2       0.25      0.27      0.26      6185\n",
            "           3       0.32      0.34      0.33      8450\n",
            "           4       0.42      0.28      0.34     16229\n",
            "           5       0.84      0.86      0.85     72560\n",
            "\n",
            "   micro avg       0.69      0.69      0.69    113691\n",
            "   macro avg       0.47      0.48      0.47    113691\n",
            "weighted avg       0.68      0.69      0.68    113691\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6L24msvtp3sV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest Model"
      ]
    },
    {
      "metadata": {
        "id": "oeAN-O1NpzDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "0c645a59-c30f-4723-aece-29fe7dc7c955"
      },
      "cell_type": "code",
      "source": [
        "#need to re-run cell for max_depth optimization and n_estimators \n",
        "from scipy.stats import randint as sp_randint\n",
        "start_time = time.time()\n",
        "param_dist = {'n_estimators':[500,700,800],\n",
        "                'criterion':['entropy'],\n",
        "                'max_depth':[6,8,10],\n",
        "                'min_samples_split': [4],\n",
        "               'max_features':sp_randint(1, 11),\n",
        "              'bootstrap': [True]\n",
        "              }\n",
        "\n",
        "rf_random_search = RandomizedSearchCV(RandomForestClassifier(class_weight ='balanced_subsample', random_state=0), param_distributions=param_dist,\n",
        "                                   n_iter=10)\n",
        "#Fit the Data\n",
        "rf_random_search.fit(X_train2_matrix, y_train2)\n",
        "print(rf_random_search.score(X_test_matrix, y_test))\n",
        "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6109190701110906\n",
            "-- Execution time: 264.1375939846039 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-gozGm8Vznoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "8691f427-6d59-4036-c7a7-c292081873b9"
      },
      "cell_type": "code",
      "source": [
        "rf_random_search.best_params_"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bootstrap': True,\n",
              " 'criterion': 'entropy',\n",
              " 'max_depth': 6,\n",
              " 'max_features': 3,\n",
              " 'min_samples_split': 4,\n",
              " 'n_estimators': 500}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "fXNBeTDI2TCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "84e3d204-3252-4b8c-a72a-15bf07eac039"
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, rf_random_search.predict(X_test_matrix)))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.44      0.58      0.50     10267\n",
            "           2       0.25      0.20      0.22      6185\n",
            "           3       0.24      0.35      0.29      8450\n",
            "           4       0.31      0.25      0.28     16229\n",
            "           5       0.79      0.76      0.78     72560\n",
            "\n",
            "   micro avg       0.61      0.61      0.61    113691\n",
            "   macro avg       0.41      0.43      0.41    113691\n",
            "weighted avg       0.62      0.61      0.61    113691\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2hIOAbiVp8ET",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### XGBoost Model"
      ]
    },
    {
      "metadata": {
        "id": "Ha6XruI8pzO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "504853f9-7362-4cc3-91d0-9ea754dd6894"
      },
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint as sp_randint\n",
        "start_time = time.time()\n",
        "param_dist = {'max_depth':[5,7,9],\n",
        "              'subsample':[0.5,0.7,0.9],\n",
        "              'colsample_bytree': [0.5,0.7,0.9],\n",
        "            'colsample_bylevel':[0.5,0.7,0.9]\n",
        "              }\n",
        "#scale_pos_weight \n",
        "xgb_random_search = RandomizedSearchCV(xgb.XGBClassifier(learning_rate =.01, random_state=0), param_distributions=param_dist,\n",
        "                                   n_iter=10)\n",
        "#Fit the Data\n",
        "xgb_random_search.fit(X_train2_matrix, y_train2)\n",
        "print(xgb_random_search.score(X_test_matrix, y_test))\n",
        "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "lGYg3S4A2bcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xgb_random_search.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NM67LTF72blZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, rxgb_random_search.predict(X_test_matrix)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIaHE_aAnHGl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model #2"
      ]
    },
    {
      "metadata": {
        "id": "f0cxBdSoUkaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "194a6c42-c6cc-4a7a-f706-f57e07009560"
      },
      "cell_type": "code",
      "source": [
        "df2 = df.copy()\n",
        "df2.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Text</th>\n",
              "      <th>Clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>Great taffy at a great price. There was a wide...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Score                                               Text  \\\n",
              "0      5  I have bought several of the Vitality canned d...   \n",
              "1      1  Product arrived labeled as Jumbo Salted Peanut...   \n",
              "2      4  This is a confection that has been around a fe...   \n",
              "3      2  If you are looking for the secret ingredient i...   \n",
              "4      5  Great taffy at a great price.  There was a wid...   \n",
              "\n",
              "                                               Clean  \n",
              "0  I have bought several of the Vitality canned d...  \n",
              "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  This is a confection that has been around a fe...  \n",
              "3  If you are looking for the secret ingredient i...  \n",
              "4  Great taffy at a great price. There was a wide...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "gDncxQX2WCwT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create training/test sets\n",
        "X = df2.Clean\n",
        "y = df2.Score\n",
        "\n",
        "#split out training/test data \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
        "\n",
        "#split training set again to test best params with reduce execution times \n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_train,y_train, test_size=0.8, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMUAXI02XSHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b3570a62-2db8-4b7d-bb74-88c126242392"
      },
      "cell_type": "code",
      "source": [
        "X_train2 = X_train2.str.cat()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-c9eb6da3eb1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'str'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VBsAJUP7SO00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bag_of_words(text):\n",
        "    allwords = [token.lemma_\n",
        "               for token in text\n",
        "               if not token.is_punct\n",
        "               and not token.is_stop]\n",
        "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
        "\n",
        "def bow_features(sentences, common_words):\n",
        "    df = pd.DataFrame(columns=common_words)\n",
        "    df['text_sentence'] = sentences[0]\n",
        "    df['text_source'] = sentences[1]\n",
        "    df.loc[:,common_words] = 0\n",
        "    \n",
        "    for i, sentence in enumerate(df['text_sentence']):\n",
        "        words = [token.lemma_ \n",
        "                for token in sentence\n",
        "                if (\n",
        "                    not token.is_punct\n",
        "                    and not token.is_stop\n",
        "                    and token.lemma_ in common_words\n",
        "                )]\n",
        "        for word in words:\n",
        "            df.loc[i, word] += 1\n",
        "        if i%500 == 0:\n",
        "            print('Processing row {}'.format(i))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8CbLSjBjUwsc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "b7ab2b55-e2f7-48be-b347-545cb8eb2b9c"
      },
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en')\n",
        "df_text = nlp(X_train2)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-521b93608087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             raise ValueError(Errors.E088.format(length=len(text),\n\u001b[0;32m--> 339\u001b[0;31m                                                 max_length=self.max_length))\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E088] Text of length 39439485 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-5ItSh0ebX6X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}