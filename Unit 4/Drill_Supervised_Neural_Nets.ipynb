{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Drill: Supervised Neural Nets",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dR6HAxdBxa9W",
        "colab_type": "code",
        "outputId": "2c180c6b-e27f-4629-d40b-5c6442545236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kIgewABCxslo",
        "colab_type": "code",
        "outputId": "3bc2fc79-7d5a-45fe-ab17-002e99d8525c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install seaborn --upgrade\n",
        "!pip install torch \n",
        "!pip install torchvision\n",
        "import torch "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seaborn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
            "\u001b[K    100% |████████████████████████████████| 215kB 28.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (0.22.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.15.2->seaborn) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.6.3)\n",
            "Installing collected packages: seaborn\n",
            "  Found existing installation: seaborn 0.7.1\n",
            "    Uninstalling seaborn-0.7.1:\n",
            "      Successfully uninstalled seaborn-0.7.1\n",
            "Successfully installed seaborn-0.9.0\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [seaborn]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n",
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 30kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x612ae000 @  0x7fa1e31ee2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-1.0.0\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 12.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Installing collected packages: pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1 torchvision-0.2.1\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [PIL]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uoj-THMXyEsC",
        "colab_type": "code",
        "outputId": "a1173dc8-d8a7-450a-e1f6-4980aeb8ef8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_on_gpu = torch.cuda.is_available\n",
        "if(train_on_gpu):\n",
        "   print('Training on GPU!')\n",
        "else:\n",
        "  print('Nope')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W_nk2dbvyZI2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hTUqi42Vyy1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "artworks = pd.read_csv('https://media.githubusercontent.com/media/MuseumofModernArt/collection/master/Artworks.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wNiV6P7Ly1ii",
        "colab_type": "code",
        "outputId": "a0bfcf24-fa06-404e-c7b1-8a31e3b2e09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "artworks.columns"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Title', 'Artist', 'ConstituentID', 'ArtistBio', 'Nationality',\n",
              "       'BeginDate', 'EndDate', 'Gender', 'Date', 'Medium', 'Dimensions',\n",
              "       'CreditLine', 'AccessionNumber', 'Classification', 'Department',\n",
              "       'DateAcquired', 'Cataloged', 'ObjectID', 'URL', 'ThumbnailURL',\n",
              "       'Circumference (cm)', 'Depth (cm)', 'Diameter (cm)', 'Height (cm)',\n",
              "       'Length (cm)', 'Weight (kg)', 'Width (cm)', 'Seat Height (cm)',\n",
              "       'Duration (sec.)'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "6T0z38Wiy3hW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Select Columns.\n",
        "artworks = artworks[['Artist', 'Nationality', 'Gender', 'Date', 'Department',\n",
        "                    'DateAcquired', 'URL', 'ThumbnailURL', 'Height (cm)', 'Width (cm)']]\n",
        "\n",
        "# Convert URL's to booleans.\n",
        "artworks['URL'] = artworks['URL'].notnull()\n",
        "artworks['ThumbnailURL'] = artworks['ThumbnailURL'].notnull()\n",
        "\n",
        "# Drop films and some other tricky rows.\n",
        "artworks = artworks[artworks['Department']!='Film']\n",
        "artworks = artworks[artworks['Department']!='Media and Performance Art']\n",
        "artworks = artworks[artworks['Department']!='Fluxus Collection']\n",
        "\n",
        "# Drop missing data.\n",
        "artworks = artworks.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HlNDULjXy5jk",
        "colab_type": "code",
        "outputId": "6965806b-7d39-48c9-aedc-c59727894928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "artworks.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist</th>\n",
              "      <th>Nationality</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Date</th>\n",
              "      <th>Department</th>\n",
              "      <th>DateAcquired</th>\n",
              "      <th>URL</th>\n",
              "      <th>ThumbnailURL</th>\n",
              "      <th>Height (cm)</th>\n",
              "      <th>Width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Otto Wagner</td>\n",
              "      <td>(Austrian)</td>\n",
              "      <td>(Male)</td>\n",
              "      <td>1896</td>\n",
              "      <td>Architecture &amp; Design</td>\n",
              "      <td>1996-04-09</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>48.6000</td>\n",
              "      <td>168.9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Christian de Portzamparc</td>\n",
              "      <td>(French)</td>\n",
              "      <td>(Male)</td>\n",
              "      <td>1987</td>\n",
              "      <td>Architecture &amp; Design</td>\n",
              "      <td>1995-01-17</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>40.6401</td>\n",
              "      <td>29.8451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Emil Hoppe</td>\n",
              "      <td>(Austrian)</td>\n",
              "      <td>(Male)</td>\n",
              "      <td>1903</td>\n",
              "      <td>Architecture &amp; Design</td>\n",
              "      <td>1997-01-15</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>34.3000</td>\n",
              "      <td>31.8000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bernard Tschumi</td>\n",
              "      <td>()</td>\n",
              "      <td>(Male)</td>\n",
              "      <td>1980</td>\n",
              "      <td>Architecture &amp; Design</td>\n",
              "      <td>1995-01-17</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>50.8000</td>\n",
              "      <td>50.8000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Emil Hoppe</td>\n",
              "      <td>(Austrian)</td>\n",
              "      <td>(Male)</td>\n",
              "      <td>1903</td>\n",
              "      <td>Architecture &amp; Design</td>\n",
              "      <td>1997-01-15</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>38.4000</td>\n",
              "      <td>19.1000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Artist Nationality  Gender  Date             Department  \\\n",
              "0               Otto Wagner  (Austrian)  (Male)  1896  Architecture & Design   \n",
              "1  Christian de Portzamparc    (French)  (Male)  1987  Architecture & Design   \n",
              "2                Emil Hoppe  (Austrian)  (Male)  1903  Architecture & Design   \n",
              "3           Bernard Tschumi          ()  (Male)  1980  Architecture & Design   \n",
              "4                Emil Hoppe  (Austrian)  (Male)  1903  Architecture & Design   \n",
              "\n",
              "  DateAcquired   URL  ThumbnailURL  Height (cm)  Width (cm)  \n",
              "0   1996-04-09  True          True      48.6000    168.9000  \n",
              "1   1995-01-17  True          True      40.6401     29.8451  \n",
              "2   1997-01-15  True          True      34.3000     31.8000  \n",
              "3   1995-01-17  True          True      50.8000     50.8000  \n",
              "4   1997-01-15  True          True      38.4000     19.1000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "Itao2zo1y7yy",
        "colab_type": "code",
        "outputId": "a205efc3-a188-4eb3-c92c-36f733791921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Get data types.\n",
        "artworks.dtypes"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Artist           object\n",
              "Nationality      object\n",
              "Gender           object\n",
              "Date             object\n",
              "Department       object\n",
              "DateAcquired     object\n",
              "URL                bool\n",
              "ThumbnailURL       bool\n",
              "Height (cm)     float64\n",
              "Width (cm)      float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "WE7gofeby9Vh",
        "colab_type": "code",
        "outputId": "4a6c8aab-c619-4ddc-c8c2-af81195a610e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "artworks['DateAcquired'] = pd.to_datetime(artworks.DateAcquired)\n",
        "artworks['YearAcquired'] = artworks.DateAcquired.dt.year\n",
        "artworks['YearAcquired'].dtype"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "0TD6Nwp2y_C0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Remove multiple nationalities, genders, and artists.\n",
        "artworks.loc[artworks['Gender'].str.contains('\\) \\('), 'Gender'] = '\\(multiple_persons\\)'\n",
        "artworks.loc[artworks['Nationality'].str.contains('\\) \\('), 'Nationality'] = '\\(multiple_nationalities\\)'\n",
        "artworks.loc[artworks['Artist'].str.contains(','), 'Artist'] = 'Multiple_Artists'\n",
        "\n",
        "# Convert dates to start date, cutting down number of distinct examples.\n",
        "artworks['Date'] = pd.Series(artworks.Date.str.extract(\n",
        "    '([0-9]{4})', expand=False))[:-1]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3wmv6ZZ1FN2D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Take sample of DataFrame for modeling purposes (computational limitations)\n",
        "artworks = artworks.sample(20000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TVVD6i3zFOgu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Final column drops and NA drop.\n",
        "X = artworks.drop(['Department', 'DateAcquired', 'Artist', 'Nationality', 'Date'], 1)\n",
        "\n",
        "# Create dummies separately.\n",
        "artists = pd.get_dummies(artworks.Artist)\n",
        "nationalities = pd.get_dummies(artworks.Nationality)\n",
        "dates = pd.get_dummies(artworks.Date)\n",
        "\n",
        "# Concat with other variables, but artists slows this wayyyyy down so we'll keep it out for now\n",
        "X = pd.get_dummies(X, sparse=True)\n",
        "X = pd.concat([X, nationalities, dates], axis=1)\n",
        "\n",
        "Y = artworks.Department"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-uluyK1KzBiG",
        "colab_type": "code",
        "outputId": "4243f9e9-73e5-4418-a1ae-533dcfeaa223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# Alright! We've done our prep, let's build the model.\n",
        "# Neural networks are hugely computationally intensive.\n",
        "# This may take several minutes to run.\n",
        "\n",
        "# Import the model.\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Establish and fit the model, with a single, 1000 perceptron layer.\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(1000,))\n",
        "mlp.fit(X, Y)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(1000,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "kFcU_jF9zDrL",
        "colab_type": "code",
        "outputId": "03370c02-df87-408b-8a10-a4d25aa7405b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "mlp.score(X, Y)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6786"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "AbtuFLbQ0eHc",
        "colab_type": "code",
        "outputId": "aa44edb3-9670-4389-94cf-2de0558fcfc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "Y.value_counts()/len(Y)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Drawings & Prints        0.62480\n",
              "Photography              0.22960\n",
              "Architecture & Design    0.11365\n",
              "Painting & Sculpture     0.03195\n",
              "Name: Department, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "tKi8KlHs0f93",
        "colab_type": "code",
        "outputId": "04024873-452c-43e5-eab7-b9a10088c470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "cross_val_score(mlp, X, Y, cv=5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.66616692, 0.27018245, 0.66725   , 0.65866467, 0.62706353])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "i3nCBXHP3FEX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Playing with Layers"
      ]
    },
    {
      "metadata": {
        "id": "F4A8JWou0g0N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vxEqTgkg3QkH",
        "colab_type": "code",
        "outputId": "388aa9ff-cc92-44d3-9e22-3508f19396fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# Establish and fit the model, with single, 1000 perceptron layer as before (now only with subset)\n",
        "mlp2 = MLPClassifier(hidden_layer_sizes=(1000,))\n",
        "mlp2.fit(X_train, y_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(1000,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "S7sxEULs3Wu5",
        "colab_type": "code",
        "outputId": "3b5dc206-a9e6-4a43-e28a-823451d7b522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "print('Cross Validation Score Training Set:', cross_val_score(mlp2, X_train, y_train, cv=5))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation Score Training Set: [0.59907176 0.73045341 0.6975     0.30178571 0.33952823]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QVNoicfb3Zu5",
        "colab_type": "code",
        "outputId": "1ff87d3a-cd0a-423c-8c4b-1840821f7d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "mlp2.score(X_test, y_test)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7303333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "9U3QALCN0-B3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ef8427d3-e0e5-4a23-f681-e4938fe3ffdc"
      },
      "cell_type": "code",
      "source": [
        "# Establish and fit the model, with two, 1000 perceptron layer.\n",
        "mlp3 = MLPClassifier(hidden_layer_sizes=(1000,1000))\n",
        "mlp3.fit(X_train, y_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(1000, 1000), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "Tf9vZSt71Lu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ccfc386-e8f4-4522-dd54-03ac68fc1aba"
      },
      "cell_type": "code",
      "source": [
        "print('Cross Validation Score Training Set:', cross_val_score(mlp3, X_train, y_train, cv=5))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation Score Training Set: [0.72831132 0.69689397 0.72964286 0.75785714 0.69692638]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H2TGMq3T1aUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c933fbd7-c71d-4289-f918-1644dbbcb662"
      },
      "cell_type": "code",
      "source": [
        "mlp3.score(X_test, y_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7726666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "_ptrb6s11Anp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0b1392c8-b41c-4468-86dd-673856bf9741"
      },
      "cell_type": "code",
      "source": [
        "# Establish and fit the model, with a single, 100 perceptron layer.\n",
        "mlp4 = MLPClassifier(hidden_layer_sizes=(100,))\n",
        "mlp4.fit(X_train, y_train)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
              "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "       validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "FEsIi1ee2JC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5dd98d9-bf95-45d0-f22b-e5b60c0ed400"
      },
      "cell_type": "code",
      "source": [
        "print('Cross Validation Score Training Set:', cross_val_score(mlp4, X_train, y_train, cv=5))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation Score Training Set: [0.53659407 0.72902535 0.66392857 0.7175     0.48606147]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Iw-k0zNW2b4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "358fbb4a-98da-4f62-86a1-cb4ee52d3093"
      },
      "cell_type": "code",
      "source": [
        "mlp4.score(X_test, y_test)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "nloHDDlzMoIw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Overall increased perceptron sizes and layers significatintly increase the computational power neccessary for execution of these models. However, it also most certainly increases the models performance.We do need to be wary of overfitting by extending the perceptron layers too far with limited data. "
      ]
    }
  ]
}