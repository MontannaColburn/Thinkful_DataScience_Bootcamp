{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP as a supervised problem",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Tn5P1v8T5qG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from nltk.corpus import gutenberg, stopwords\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v_entvLCAZfq",
        "colab_type": "code",
        "outputId": "d2363260-5991-4260-f328-7fbd428b8f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# Launch the installer to download \"gutenberg\" and \"stop words\" corpora.\n",
        "nltk.download()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> gutenberg\n",
            "    Downloading package gutenberg to /root/nltk_data...\n",
            "      Package gutenberg is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n",
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Package stopwords is already up-to-date!\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "5cBQYRC65rW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utility function for standard text cleaning.\n",
        "def text_cleaner(text):\n",
        "    # Visual inspection identifies a form of punctuation spaCy does not\n",
        "    # recognize: the double dash '--'.  Better get rid of it now!\n",
        "    text = re.sub(r'--',' ',text)\n",
        "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "    \n",
        "# Load and clean the data.\n",
        "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
        "alice = gutenberg.raw('carroll-alice.txt')\n",
        "\n",
        "# The Chapter indicator is idiosyncratic\n",
        "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
        "alice = re.sub(r'CHAPTER .*', '', alice)\n",
        "    \n",
        "alice = text_cleaner(alice)\n",
        "persuasion = text_cleaner(persuasion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wfPCUULE523P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parse the cleaned novels. This can take a bit.\n",
        "nlp = spacy.load('en')\n",
        "alice_doc = nlp(alice)\n",
        "persuasion_doc = nlp(persuasion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-zqGr9z75-oX",
        "colab_type": "code",
        "outputId": "ba5bc4ab-5d39-4abf-9b91-8e1664e7666f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# Group into sentences.\n",
        "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
        "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
        "\n",
        "print(len(alice_sents))\n",
        "print(len(persuasion_sents))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1669\n",
            "3649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dMrCqLKeSc3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "342c6544-7a93-4af6-91a8-88f9051e5013"
      },
      "cell_type": "code",
      "source": [
        "#due to computational limitations, reduce length of alice_sents to 1000\n",
        "alice_sents = alice_sents[0:1000]\n",
        "persuasion_sents = persuasion_sents[0:1000]\n",
        "\n",
        "print(len(alice_sents))\n",
        "print(len(persuasion_sents))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7wjR8dddS9UQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "25d4c71e-7d75-43fc-fe33-a66c3a8729e6"
      },
      "cell_type": "code",
      "source": [
        "# Combine the sentences from the two novels into one data frame.\n",
        "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
        "sentences.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0        1\n",
              "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
              "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
              "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
              "3                                      (Oh, dear, !)  Carroll\n",
              "4                         (I, shall, be, late, !, ')  Carroll"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "aoLYniUO6b7j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utility function to create a list of the 2000 most common words.\n",
        "def bag_of_words(text):\n",
        "    \n",
        "    # Filter out punctuation and stop words.\n",
        "    allwords = [token.lemma_\n",
        "                for token in text\n",
        "                if not token.is_punct\n",
        "                and not token.is_stop]\n",
        "    \n",
        "    # Return the most common words.\n",
        "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
        "    \n",
        "\n",
        "# Creates a data frame with features for each word in our common word set.\n",
        "# Each value is the count of the times the word appears in each sentence.\n",
        "def bow_features(sentences, common_words):\n",
        "    \n",
        "    # Scaffold the data frame and initialize counts to zero.\n",
        "    df = pd.DataFrame(columns=common_words)\n",
        "    df['text_sentence'] = sentences[0]\n",
        "    df['text_source'] = sentences[1]\n",
        "    df.loc[:, common_words] = 0\n",
        "    \n",
        "    # Process each row, counting the occurrence of words in each sentence.\n",
        "    for i, sentence in enumerate(df['text_sentence']):\n",
        "        \n",
        "        # Convert the sentence to lemmas, then filter out punctuation,\n",
        "        # stop words, and uncommon words.\n",
        "        words = [token.lemma_\n",
        "                 for token in sentence\n",
        "                 if (\n",
        "                     not token.is_punct\n",
        "                     and not token.is_stop\n",
        "                     and token.lemma_ in common_words\n",
        "                 )]\n",
        "        \n",
        "        # Populate the row with word counts.\n",
        "        for word in words:\n",
        "            df.loc[i, word] += 1\n",
        "        \n",
        "        # This counter is just to make sure the kernel didn't hang.\n",
        "        if i % 500 == 0:\n",
        "            print(\"Processing row {}\".format(i))\n",
        "            \n",
        "    return df\n",
        "\n",
        "# Set up the bags.\n",
        "alicewords = bag_of_words(alice_doc)\n",
        "persuasionwords = bag_of_words(persuasion_doc)\n",
        "\n",
        "# Combine bags to create a set of unique words.\n",
        "common_words = set(alicewords + persuasionwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i-F-Y7cf7QyA",
        "colab_type": "code",
        "outputId": "e7b86b42-0450-43da-8d9a-925b64562105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "# Create our data frame with features. This can take a while to run.\n",
        "import time\n",
        "start_time = time.time()\n",
        "word_counts = bow_features(sentences, common_words)\n",
        "print(\"-- Execution time: %s seconds ---\" % (time.time() - start_time))\n",
        "word_counts.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing row 0\n",
            "Processing row 500\n",
            "Processing row 1000\n",
            "Processing row 1500\n",
            "-- Execution time: 4782.072224378586 seconds ---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bird</th>\n",
              "      <th>calmly</th>\n",
              "      <th>season</th>\n",
              "      <th>noise</th>\n",
              "      <th>dry</th>\n",
              "      <th>ambition</th>\n",
              "      <th>recover</th>\n",
              "      <th>evening</th>\n",
              "      <th>between</th>\n",
              "      <th>uppercross</th>\n",
              "      <th>...</th>\n",
              "      <th>sorrowful</th>\n",
              "      <th>drown</th>\n",
              "      <th>sky</th>\n",
              "      <th>plan</th>\n",
              "      <th>give</th>\n",
              "      <th>deserted</th>\n",
              "      <th>est</th>\n",
              "      <th>happiness</th>\n",
              "      <th>text_sentence</th>\n",
              "      <th>text_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3064 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  bird calmly season noise dry ambition recover evening between uppercross  \\\n",
              "0    0      0      0     0   0        0       0       0       0          0   \n",
              "1    0      0      0     0   0        0       0       0       0          0   \n",
              "2    0      0      0     0   0        0       0       0       0          0   \n",
              "3    0      0      0     0   0        0       0       0       0          0   \n",
              "4    0      0      0     0   0        0       0       0       0          0   \n",
              "\n",
              "      ...     sorrowful drown sky plan give deserted est happiness  \\\n",
              "0     ...             0     0   0    0    0        0   0         0   \n",
              "1     ...             0     0   0    0    0        0   0         0   \n",
              "2     ...             0     0   0    0    0        0   0         0   \n",
              "3     ...             0     0   0    0    0        0   0         0   \n",
              "4     ...             0     0   0    0    0        0   0         0   \n",
              "\n",
              "                                       text_sentence text_source  \n",
              "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
              "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
              "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
              "3                                      (Oh, dear, !)     Carroll  \n",
              "4                         (I, shall, be, late, !, ')     Carroll  \n",
              "\n",
              "[5 rows x 3064 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "nMX-ZNH77yua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "ab415fb8-2aec-4205-9c7c-9aaa3e09efde"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "rfc = ensemble.RandomForestClassifier()\n",
        "Y = word_counts['text_source']\n",
        "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.4,\n",
        "                                                    random_state=0)\n",
        "train = rfc.fit(X_train, y_train)\n",
        "\n",
        "print('Training set score:', rfc.score(X_train, y_train))\n",
        "print('\\nTest set score:', rfc.score(X_test, y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.9875\n",
            "\n",
            "Test set score: 0.84875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bCzZZ8Ee8edz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "d89ce670-6af8-4624-f663-a4b30d8aec43"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "train = lr.fit(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1200, 3062) (1200,)\n",
            "Training set score: 0.9716666666666667\n",
            "\n",
            "Test set score: 0.87875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rf3eqLOc8iz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3b103602-f48e-45b6-d40f-c205f6c92957"
      },
      "cell_type": "code",
      "source": [
        "clf = ensemble.GradientBoostingClassifier()\n",
        "train = clf.fit(X_train, y_train)\n",
        "\n",
        "print('Training set score:', clf.score(X_train, y_train))\n",
        "print('\\nTest set score:', clf.score(X_test, y_test))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.8808333333333334\n",
            "\n",
            "Test set score: 0.80625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1FSueJ6I8kth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "27ec1cf1-7c9d-4308-a4d8-3f6dd68de193"
      },
      "cell_type": "code",
      "source": [
        "# Clean the Emma data.\n",
        "emma = gutenberg.raw('austen-emma.txt')\n",
        "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
        "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
        "emma = text_cleaner(emma)\n",
        "print(emma[:100])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DmqXiOir86v4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parse our cleaned data.\n",
        "emma_doc = nlp(emma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_swQrrHp88_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Group into sentences.\n",
        "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
        "emma_sents = [[sent, \"Austen\"] for sent in emma_doc.sents]\n",
        "\n",
        "# Emma is quite long, let's cut it down to the same length as Alice.\n",
        "emma_sents = emma_sents[0:len(alice_sents)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y00xJYyR-lfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4a1e691e-c4fe-4b56-a7e0-550879c0ddb2"
      },
      "cell_type": "code",
      "source": [
        "# Build a new Bag of Words data frame for Emma word counts.\n",
        "# We'll use the same common words from Alice and Persuasion.\n",
        "emma_sentences = pd.DataFrame(emma_sents)\n",
        "emma_bow = bow_features(emma_sentences, common_words)\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing row 0\n",
            "Processing row 500\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sQR0Priz-8OF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "796ecd16-6ad4-4ca0-d2bd-126d74178111"
      },
      "cell_type": "code",
      "source": [
        "# Now we can model it!\n",
        "# Let's use logistic regression again.\n",
        "\n",
        "# Combine the Emma sentence data with the Alice data from the test set.\n",
        "X_Emma_test = np.concatenate((\n",
        "    X_train[y_train[y_train=='Carroll'].index],\n",
        "    emma_bow.drop(['text_sentence','text_source'], 1)\n",
        "), axis=0)\n",
        "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
        "                         pd.Series(['Austen'] * emma_bow.shape[0])])\n",
        "\n",
        "# Model.\n",
        "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
        "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
        "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set score: 0.6633102580239144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>Austen</th>\n",
              "      <th>Carroll</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Austen</th>\n",
              "      <td>772</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Carroll</th>\n",
              "      <td>307</td>\n",
              "      <td>282</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    Austen  Carroll\n",
              "row_0                   \n",
              "Austen      772      228\n",
              "Carroll     307      282"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "xsnljiJ3_S6l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Challenge 0: \n",
        "\n",
        "Recall that the logistic regression model's best performance on the test set was 93%. See what you can do to improve performance. Suggested avenues of investigation include: Other modeling techniques (SVM?), making more features that take advantage of the spaCy information (include grammar, phrases, POS, etc), making sentence-level features (number of words, amount of punctuation), or including contextual information (length of previous and next sentences, words repeated from one sentence to the next, etc), and anything else your heart desires. Make sure to design your models on the test set, or use cross_validation with multiple folds, and see if you can get accuracy above 90%."
      ]
    },
    {
      "metadata": {
        "id": "ID7Svo5HIJLQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Feature Eng. \n",
        "\n",
        "#word count per sentence\n",
        "sentences = word_counts.text_sentence\n",
        "word_counts['sentence_len'] = [len(i) for i in sentences]\n",
        "\n",
        "#noun count per sentence\n",
        "nouns = []\n",
        "for sent in sentences: \n",
        "  noun = 0 \n",
        "  for token in sent: \n",
        "    noun = noun + token.pos_.count('NOUN')\n",
        "  word_counts['nouns'] = noun \n",
        "\n",
        "#verb count per sentence\n",
        "verbs = []\n",
        "for sent in sentences: \n",
        "  verb = 0 \n",
        "  for token in sent: \n",
        "    verb = verb + token.pos_.count('VERB')\n",
        "  word_counts['verbs'] = verb \n",
        "   \n",
        "#adjective count per sentence\n",
        "adjectives = []\n",
        "for sent in sentences: \n",
        "  adjective = 0 \n",
        "  for token in sent: \n",
        "    adjective = adjective + token.pos_.count('ADJ')\n",
        "  word_counts['adjectives'] = adjective\n",
        "   \n",
        "#proper noun count per sentence\n",
        "propers = []\n",
        "for sent in sentences: \n",
        "  proper = 0 \n",
        "  for token in sent: \n",
        "    proper = proper + token.pos_.count('PROPN')\n",
        "  word_counts['propers'] = proper\n",
        "  \n",
        "#punctuation count per sentence\n",
        "punctuations = []\n",
        "for sent in sentences: \n",
        "  punctuation = 0 \n",
        "  for token in sent: \n",
        "    punctuation = punctuation + token.pos_.count('PUNCT')\n",
        "  word_counts['punctuations'] = punctuation  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rOcV7vRGNsbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "2e942b07-e4da-4da8-f868-092f17d509a8"
      },
      "cell_type": "code",
      "source": [
        "##Check updated DF \n",
        "word_counts.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bird</th>\n",
              "      <th>calmly</th>\n",
              "      <th>season</th>\n",
              "      <th>noise</th>\n",
              "      <th>dry</th>\n",
              "      <th>ambition</th>\n",
              "      <th>recover</th>\n",
              "      <th>evening</th>\n",
              "      <th>between</th>\n",
              "      <th>uppercross</th>\n",
              "      <th>...</th>\n",
              "      <th>est</th>\n",
              "      <th>happiness</th>\n",
              "      <th>text_sentence</th>\n",
              "      <th>text_source</th>\n",
              "      <th>sentence_len</th>\n",
              "      <th>nouns</th>\n",
              "      <th>verbs</th>\n",
              "      <th>punctuations</th>\n",
              "      <th>adjectives</th>\n",
              "      <th>propers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>67</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>63</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>33</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3070 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  bird calmly season noise dry ambition recover evening between uppercross  \\\n",
              "0    0      0      0     0   0        0       0       0       0          0   \n",
              "1    0      0      0     0   0        0       0       0       0          0   \n",
              "2    0      0      0     0   0        0       0       0       0          0   \n",
              "3    0      0      0     0   0        0       0       0       0          0   \n",
              "4    0      0      0     0   0        0       0       0       0          0   \n",
              "\n",
              "    ...   est happiness                                      text_sentence  \\\n",
              "0   ...     0         0  (Alice, was, beginning, to, get, very, tired, ...   \n",
              "1   ...     0         0  (So, she, was, considering, in, her, own, mind...   \n",
              "2   ...     0         0  (There, was, nothing, so, VERY, remarkable, in...   \n",
              "3   ...     0         0                                      (Oh, dear, !)   \n",
              "4   ...     0         0                         (I, shall, be, late, !, ')   \n",
              "\n",
              "  text_source sentence_len nouns verbs punctuations adjectives propers  \n",
              "0     Carroll           67     3     5            3          2       0  \n",
              "1     Carroll           63     3     5            3          2       0  \n",
              "2     Carroll           33     3     5            3          2       0  \n",
              "3     Carroll            3     3     5            3          2       0  \n",
              "4     Carroll            6     3     5            3          2       0  \n",
              "\n",
              "[5 rows x 3070 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "AGnsK9e-Nuyv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Split data for training purposes\n",
        "Y = word_counts['text_source']\n",
        "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.4,\n",
        "                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "476rMxJxNx86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "ae883b25-42c9-4525-8f58-7dd863d2e224"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "#fit logistic regression with updated DF \n",
        "lr = LogisticRegression()\n",
        "train = lr.fit(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "print('\\nCross Val score:',cross_val_score(lr, X_test, y_test, cv=5))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1200, 3068) (1200,)\n",
            "Training set score: 0.9808333333333333\n",
            "\n",
            "Test set score: 0.87625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Cross Val score: [0.85714286 0.90625    0.84375    0.90625    0.8490566 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HdIgJz1j_c3n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Challenge 1:\n",
        "\n",
        "Find out whether your new model is good at identifying Alice in Wonderland vs any other work, Persuasion vs any other work, or Austen vs any other work. This will involve pulling a new book from the Project Gutenberg corpus (print(gutenberg.fileids()) for a list) and processing it.\n",
        "\n",
        "Record your work for each challenge in a notebook and submit it below."
      ]
    },
    {
      "metadata": {
        "id": "1Wx-2-wX_eqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bc2b0bd0-496d-4f78-bc78-784607e0450a"
      },
      "cell_type": "code",
      "source": [
        "# Bring in/clean the shakespeare data.\n",
        "hamlet = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "hamlet = re.sub(r'VOLUME \\w+', '', hamlet)\n",
        "hamlet = re.sub(r'CHAPTER \\w+', '', hamlet)\n",
        "hamlet = text_cleaner(hamlet)\n",
        "print(hamlet[:100])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actus Primus. Scoena Prima. Enter Barnardo and Francisco two Centinels. Barnardo. Who's there? Fran.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y4vCqRJ2WZ74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1d73ac25-311c-4443-b823-071b961ced58"
      },
      "cell_type": "code",
      "source": [
        "print(len(hamlet))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "158933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cBFdK09nOOjG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parse our cleaned data.\n",
        "hamlet_doc = nlp(hamlet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YamAyE9qXYZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "86d60539-7bf4-44cb-cff8-385744462a89"
      },
      "cell_type": "code",
      "source": [
        "# Group into sentences.\n",
        "hamlet_sents = [[sent, \"Shakespeare\"] for sent in hamlet_doc.sents]\n",
        "\n",
        "print(len(hamlet_sents))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bvw7i8TgXasD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Due to computational limitations, reduce length of hamlet_sents to 1000\n",
        "hamlet_sents = hamlet_sents[0:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "atmNn5R8X1LH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "846beb20-26f0-4c05-e50e-fc22e6022878"
      },
      "cell_type": "code",
      "source": [
        "# Combine the sentences from the two novels into one data frame.\n",
        "sentences = pd.DataFrame(alice_sents + hamlet_sents)\n",
        "sentences.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0        1\n",
              "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
              "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
              "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
              "3                                      (Oh, dear, !)  Carroll\n",
              "4                         (I, shall, be, late, !, ')  Carroll"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "pJRgnGcqdw17",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up the bags of words.\n",
        "hamletwords = bag_of_words(hamlet_doc)\n",
        "common_words = set(alicewords+hamletwords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ec16q0SOTVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "f6179695-4120-4233-ba20-2d82f55d457f"
      },
      "cell_type": "code",
      "source": [
        "# Build a new Bag of Words data frame for Hamlet word counts.\n",
        "# We'll use the same common words from Alice and Persuasion.\n",
        "hamlet_bow = bow_features(sentences, common_words)\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing row 0\n",
            "Processing row 500\n",
            "Processing row 1000\n",
            "Processing row 1500\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n9t7S5rlbYyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "280f8cbd-bf4a-4ed3-fcc3-81213590a1ce"
      },
      "cell_type": "code",
      "source": [
        "hamlet_bow.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bird</th>\n",
              "      <th>calmly</th>\n",
              "      <th>season</th>\n",
              "      <th>noise</th>\n",
              "      <th>dry</th>\n",
              "      <th>dreadfull</th>\n",
              "      <th>ambition</th>\n",
              "      <th>recover</th>\n",
              "      <th>evening</th>\n",
              "      <th>between</th>\n",
              "      <th>...</th>\n",
              "      <th>sorrowful</th>\n",
              "      <th>drown</th>\n",
              "      <th>sky</th>\n",
              "      <th>plan</th>\n",
              "      <th>give</th>\n",
              "      <th>elsonower</th>\n",
              "      <th>aloofe</th>\n",
              "      <th>est</th>\n",
              "      <th>text_sentence</th>\n",
              "      <th>text_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(Oh, dear, !)</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>(I, shall, be, late, !, ')</td>\n",
              "      <td>Carroll</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3356 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  bird calmly season noise dry dreadfull ambition recover evening between  \\\n",
              "0    0      0      0     0   0         0        0       0       0       0   \n",
              "1    0      0      0     0   0         0        0       0       0       0   \n",
              "2    0      0      0     0   0         0        0       0       0       0   \n",
              "3    0      0      0     0   0         0        0       0       0       0   \n",
              "4    0      0      0     0   0         0        0       0       0       0   \n",
              "\n",
              "      ...     sorrowful drown sky plan give elsonower aloofe est  \\\n",
              "0     ...             0     0   0    0    0         0      0   0   \n",
              "1     ...             0     0   0    0    0         0      0   0   \n",
              "2     ...             0     0   0    0    0         0      0   0   \n",
              "3     ...             0     0   0    0    0         0      0   0   \n",
              "4     ...             0     0   0    0    0         0      0   0   \n",
              "\n",
              "                                       text_sentence text_source  \n",
              "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
              "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
              "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
              "3                                      (Oh, dear, !)     Carroll  \n",
              "4                         (I, shall, be, late, !, ')     Carroll  \n",
              "\n",
              "[5 rows x 3356 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "91XrBVIVOVcl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Same feature eng. as previously done \n",
        "\n",
        "#word count per sentence\n",
        "sentences = hamlet_bow.text_sentence\n",
        "hamlet_bow['sentence_len'] = [len(i) for i in sentences]\n",
        "\n",
        "#noun count per sentence\n",
        "nouns = []\n",
        "for sent in sentences: \n",
        "  noun = 0 \n",
        "  for token in sent: \n",
        "    noun = noun + token.pos_.count('NOUN')\n",
        "  hamlet_bow['nouns'] = noun \n",
        "\n",
        "#verb count per sentence\n",
        "verbs = []\n",
        "for sent in sentences: \n",
        "  verb = 0 \n",
        "  for token in sent: \n",
        "    verb = verb + token.pos_.count('VERB')\n",
        "  hamlet_bow['verbs'] = verb \n",
        "  \n",
        "#adjective count per sentence\n",
        "adjectives = []\n",
        "for sent in sentences: \n",
        "  adjective = 0 \n",
        "  for token in sent: \n",
        "    adjective = adjective + token.pos_.count('ADJ')\n",
        "  hamlet_bow['adjectives'] = adjective\n",
        "   \n",
        "#proper noun count per sentence\n",
        "propers = []\n",
        "for sent in sentences: \n",
        "  proper = 0 \n",
        "  for token in sent: \n",
        "    proper = proper + token.pos_.count('PROPN')\n",
        "  hamlet_bow['propers'] = proper\n",
        "  \n",
        "#punctuation count per sentence\n",
        "punctuations = []\n",
        "for sent in sentences: \n",
        "  punctuation = 0 \n",
        "  for token in sent: \n",
        "    punctuation = punctuation + token.pos_.count('PUNCT')\n",
        "  hamlet_bow['punctuations'] = punctuation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c2bw-EAaOZBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y = hamlet_bow['text_source']\n",
        "X = np.array(hamlet_bow.drop(['text_sentence','text_source'], 1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.4,\n",
        "                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fAtj8UomOb0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "7a8b9627-0b0c-4e69-9c82-c160174c1dbf"
      },
      "cell_type": "code",
      "source": [
        "#fit logistic regression with hamlet data \n",
        "lr = LogisticRegression()\n",
        "train = lr.fit(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print('Training set score:', lr.score(X_train, y_train))\n",
        "print('\\nTest set score:', lr.score(X_test, y_test))\n",
        "print('\\nCross Val score:',cross_val_score(lr, X_test, y_test, cv=5))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1200, 3360) (1200,)\n",
            "Training set score: 0.9683333333333334\n",
            "\n",
            "Test set score: 0.8975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Cross Val score: [0.90062112 0.85       0.875      0.89375    0.89937107]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nXoHksEHkCHI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#t-SNE data visualization with words etc. "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}