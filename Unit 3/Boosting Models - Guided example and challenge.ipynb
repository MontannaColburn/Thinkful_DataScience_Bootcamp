{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
      "0     CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
      "1     CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
      "2     CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
      "3     CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
      "4     CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
      "6     CH  40.0     6    3.0      0.0      5.0     2.0    0.0      2.0     2.0   \n",
      "7     CH  41.0     6    2.0      4.0      5.0     3.0   10.0      5.0     2.0   \n",
      "8     CH  51.0     6    2.0      8.0      8.0     8.0    9.0      6.0     4.0   \n",
      "9     CH  53.0     6    4.0      4.0      4.0     8.0    7.0      4.0     2.0   \n",
      "10    CH  55.0     6    1.0      6.0      7.0     7.0    9.0      5.0     2.0   \n",
      "\n",
      "    gndr  agea  partner  \n",
      "0    2.0  60.0      1.0  \n",
      "1    2.0  59.0      1.0  \n",
      "2    1.0  24.0      2.0  \n",
      "3    2.0  64.0      1.0  \n",
      "4    2.0  55.0      1.0  \n",
      "6    1.0  76.0      1.0  \n",
      "7    2.0  30.0      1.0  \n",
      "8    2.0  84.0      2.0  \n",
      "9    2.0  62.0      1.0  \n",
      "10   2.0  33.0      1.0  \n",
      "      year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  gndr  \\\n",
      "0        6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   2.0   \n",
      "1        6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   2.0   \n",
      "2        6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   1.0   \n",
      "3        6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   2.0   \n",
      "4        6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   2.0   \n",
      "6        6    3.0      0.0      5.0     2.0    0.0      2.0     2.0   1.0   \n",
      "7        6    2.0      4.0      5.0     3.0   10.0      5.0     2.0   2.0   \n",
      "8        6    2.0      8.0      8.0     8.0    9.0      6.0     4.0   2.0   \n",
      "9        6    4.0      4.0      4.0     8.0    7.0      4.0     2.0   2.0   \n",
      "10       6    1.0      6.0      7.0     7.0    9.0      5.0     2.0   2.0   \n",
      "11       6    4.0      5.0      7.0     7.0    7.0      5.0     3.0   1.0   \n",
      "12       6    4.0      7.0      7.0     4.0    9.0      6.0     2.0   1.0   \n",
      "13       6    2.0      1.0      9.0     7.0    8.0      4.0     3.0   1.0   \n",
      "14       6    4.0      4.0      5.0     3.0    8.0      1.0     2.0   2.0   \n",
      "15       6    5.0      4.0      5.0     5.0    9.0      3.0     3.0   2.0   \n",
      "16       6    4.0      5.0      7.0     7.0    8.0      3.0     3.0   1.0   \n",
      "17       6    2.0      7.0      7.0     7.0    6.0      6.0     3.0   1.0   \n",
      "18       6    0.0      9.0      7.0     8.0    9.0      5.0     4.0   1.0   \n",
      "19       6    2.0      6.0      6.0     6.0    8.0      4.0     3.0   2.0   \n",
      "20       6    7.0      3.0      4.0     4.0    7.0      6.0     4.0   1.0   \n",
      "21       6    1.0      8.0      8.0     6.0    8.0      7.0     4.0   1.0   \n",
      "22       6    2.0      7.0      7.0     8.0    9.0      6.0     3.0   1.0   \n",
      "23       6    2.0      4.0      8.0     8.0    9.0      6.0     2.0   2.0   \n",
      "24       6    0.0      7.0      7.0     4.0    9.0      4.0     2.0   2.0   \n",
      "25       6    0.0      6.0      7.0     5.0    7.0      6.0     2.0   2.0   \n",
      "26       6    2.0      7.0      6.0     5.0    8.0      4.0     3.0   2.0   \n",
      "27       6    0.0      5.0      8.0     6.0    9.0      4.0     2.0   2.0   \n",
      "28       6    2.0      8.0      8.0     8.0   10.0      6.0     3.0   2.0   \n",
      "29       6    7.0      8.0      5.0     5.0    8.0      5.0     3.0   2.0   \n",
      "30       6    6.0      8.0      8.0     3.0    5.0      6.0     1.0   2.0   \n",
      "...    ...    ...      ...      ...     ...    ...      ...     ...   ...   \n",
      "8564     7    2.0      1.0      5.0     4.0   10.0      7.0     4.0   1.0   \n",
      "8565     7    5.0      5.0      3.0     4.0    5.0      6.0     1.0   2.0   \n",
      "8566     7    2.0      7.0      8.0     6.0    8.0      7.0     3.0   2.0   \n",
      "8567     7    2.0      4.0      8.0     7.0    9.0      7.0     4.0   2.0   \n",
      "8568     7    1.0      2.0      8.0     6.0    9.0      7.0     3.0   2.0   \n",
      "8569     7    6.0      5.0      3.0     4.0    9.0      6.0     4.0   1.0   \n",
      "8570     7    1.0      5.0      7.0     7.0    8.0      7.0     4.0   1.0   \n",
      "8571     7    3.0      4.0      9.0     7.0    8.0      6.0     3.0   1.0   \n",
      "8572     7    5.0      7.0      8.0     5.0    8.0      3.0     1.0   1.0   \n",
      "8573     7    1.0      8.0      8.0     6.0    9.0      7.0     3.0   2.0   \n",
      "8574     7    1.0      4.0      5.0     6.0    7.0      7.0     3.0   2.0   \n",
      "8575     7    3.0      8.0      7.0     7.0    8.0      7.0     3.0   1.0   \n",
      "8576     7    4.0      5.0      4.0     4.0    7.0      6.0     3.0   1.0   \n",
      "8577     7    6.0      6.0      9.0     7.0    5.0      4.0     2.0   2.0   \n",
      "8578     7    1.0      5.0      5.0     5.0    7.0      5.0     4.0   2.0   \n",
      "8579     7    2.0      8.0      9.0     7.0    9.0      7.0     3.0   2.0   \n",
      "8580     7    4.0      7.0      8.0     5.0   10.0      4.0     1.0   1.0   \n",
      "8581     7    1.0      6.0      7.0     6.0    8.0      6.0     3.0   1.0   \n",
      "8582     7    6.0      7.0      7.0     6.0    8.0      7.0     3.0   1.0   \n",
      "8583     7    2.0      6.0      8.0     5.0   10.0      6.0     5.0   1.0   \n",
      "8584     7    2.0      8.0     10.0     6.0    9.0      6.0     2.0   1.0   \n",
      "8585     7    1.0      3.0      6.0     4.0    9.0      7.0     3.0   1.0   \n",
      "8586     7    2.0      4.0      6.0     3.0    7.0      7.0     3.0   2.0   \n",
      "8587     7    4.0      4.0      6.0     7.0    9.0      7.0     3.0   1.0   \n",
      "8588     7    1.0      6.0      5.0     5.0   10.0      7.0     2.0   1.0   \n",
      "8589     7    3.0      4.0      5.0     3.0    6.0      6.0     2.0   1.0   \n",
      "8590     7    5.0      6.0      4.0     4.0   10.0      6.0     3.0   1.0   \n",
      "8591     7    4.0      5.0      7.0     6.0    8.0      6.0     3.0   1.0   \n",
      "8592     7    5.0      8.0      8.0     6.0    9.0      7.0     3.0   1.0   \n",
      "8593     7    2.0      6.0      7.0     5.0    7.0      7.0     4.0   2.0   \n",
      "\n",
      "      agea  CH  CZ  DE  ES  NO  SE  \n",
      "0     60.0   1   0   0   0   0   0  \n",
      "1     59.0   1   0   0   0   0   0  \n",
      "2     24.0   1   0   0   0   0   0  \n",
      "3     64.0   1   0   0   0   0   0  \n",
      "4     55.0   1   0   0   0   0   0  \n",
      "6     76.0   1   0   0   0   0   0  \n",
      "7     30.0   1   0   0   0   0   0  \n",
      "8     84.0   1   0   0   0   0   0  \n",
      "9     62.0   1   0   0   0   0   0  \n",
      "10    33.0   1   0   0   0   0   0  \n",
      "11    40.0   1   0   0   0   0   0  \n",
      "12    69.0   1   0   0   0   0   0  \n",
      "13    59.0   1   0   0   0   0   0  \n",
      "14    32.0   1   0   0   0   0   0  \n",
      "15    70.0   1   0   0   0   0   0  \n",
      "16    61.0   1   0   0   0   0   0  \n",
      "17    30.0   1   0   0   0   0   0  \n",
      "18    21.0   1   0   0   0   0   0  \n",
      "19    36.0   1   0   0   0   0   0  \n",
      "20    51.0   1   0   0   0   0   0  \n",
      "21    25.0   1   0   0   0   0   0  \n",
      "22    62.0   1   0   0   0   0   0  \n",
      "23    20.0   1   0   0   0   0   0  \n",
      "24    22.0   1   0   0   0   0   0  \n",
      "25    32.0   1   0   0   0   0   0  \n",
      "26    35.0   1   0   0   0   0   0  \n",
      "27    26.0   1   0   0   0   0   0  \n",
      "28    35.0   1   0   0   0   0   0  \n",
      "29    54.0   1   0   0   0   0   0  \n",
      "30    38.0   1   0   0   0   0   0  \n",
      "...    ...  ..  ..  ..  ..  ..  ..  \n",
      "8564  17.0   0   0   0   0   0   1  \n",
      "8565  17.0   0   0   0   0   0   1  \n",
      "8566  17.0   0   0   0   0   0   1  \n",
      "8567  17.0   0   0   0   0   0   1  \n",
      "8568  17.0   0   0   0   0   0   1  \n",
      "8569  17.0   0   0   0   0   0   1  \n",
      "8570  16.0   0   0   0   0   0   1  \n",
      "8571  16.0   0   0   0   0   0   1  \n",
      "8572  16.0   0   0   0   0   0   1  \n",
      "8573  16.0   0   0   0   0   0   1  \n",
      "8574  16.0   0   0   0   0   0   1  \n",
      "8575  16.0   0   0   0   0   0   1  \n",
      "8576  16.0   0   0   0   0   0   1  \n",
      "8577  16.0   0   0   0   0   0   1  \n",
      "8578  16.0   0   0   0   0   0   1  \n",
      "8579  16.0   0   0   0   0   0   1  \n",
      "8580  16.0   0   0   0   0   0   1  \n",
      "8581  16.0   0   0   0   0   0   1  \n",
      "8582  16.0   0   0   0   0   0   1  \n",
      "8583  16.0   0   0   0   0   0   1  \n",
      "8584  16.0   0   0   0   0   0   1  \n",
      "8585  16.0   0   0   0   0   0   1  \n",
      "8586  15.0   0   0   0   0   0   1  \n",
      "8587  15.0   0   0   0   0   0   1  \n",
      "8588  15.0   0   0   0   0   0   1  \n",
      "8589  18.0   0   0   0   0   0   1  \n",
      "8590  15.0   0   0   0   0   0   1  \n",
      "8591  44.0   0   0   0   0   0   1  \n",
      "8592  15.0   0   0   0   0   0   1  \n",
      "8593  15.0   0   0   0   0   0   1  \n",
      "\n",
      "[8147 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "print(df.head(10))\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "print(X)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A type I error is a false positive finding, while a type II error is a false negative finding. Looks like we're getting more false negatives here, thus identifying those with a partner as without.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRILL: Improve this gradient boost model\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement. Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set. Strategies you might use include:\n",
    "\n",
    "Creating new features\n",
    "\n",
    "Applying more overfitting-prevention strategies like subsampling\n",
    "\n",
    "More iterations\n",
    "\n",
    "Trying a different loss function\n",
    "\n",
    "Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check correlated values and use PCA to combine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7493188 , 0.77520436, 0.70572207, 0.72070845, 0.76944065,\n",
       "       0.75716235, 0.75443383, 0.74351978, 0.73087432, 0.40846995])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(clf, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x124e5bf0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=9)\n",
    "X_pca = sklearn_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7332, 9)\n",
      "(7332,)\n"
     ]
    }
   ],
   "source": [
    "# Create training and test sets.\n",
    "offset = int(X_pca.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X_pca[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X_pca[offset:], y[offset:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.037506819421713036\n",
      "Percent Type II errors: 0.16775777414075285\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05889570552147239\n",
      "Percent Type II errors: 0.2049079754601227\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Looks like we actually did slightly worse this go around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now try changing the loss function to expontential and see how this affects the outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03805237315875614\n",
      "Percent Type II errors: 0.1718494271685761\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.05521472392638037\n",
      "Percent Type II errors: 0.20245398773006135\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use -deep trees, and set our loss function to expontential .\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'exponential'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0]/table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0]/table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion : A bit better on the training set for both, but only slightly better on the test set type I error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now increase the number of iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.03314238952536825\n",
      "Percent Type II errors: 0.15439170758319695\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.07116564417177915\n",
      "Percent Type II errors: 0.19754601226993865\n"
     ]
    }
   ],
   "source": [
    "# We'll make 1000 iterations, use -deep trees, and set our loss function to expontential .\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'exponential'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0]/table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0]/table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Appears we've gotten worse at type I errors, but better on our type II errors on our test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now deepen our decision trees a bit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0023186033824331696\n",
      "Percent Type II errors: 0.044053464266230226\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.08711656441717791\n",
      "Percent Type II errors: 0.19631901840490798\n"
     ]
    }
   ],
   "source": [
    "# We'll make 1000 iterations, use -deep trees, and set our loss function to expontential .\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 4,\n",
    "          'loss': 'exponential'}\n",
    "    \n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0]/table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0]/table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: well we did much better in our training set, but it seems our test set only slightly improved for type II errors and got slightly worse at type I errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now try subsampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.004637206764866339\n",
      "Percent Type II errors: 0.031096563011456628\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.09202453987730061\n",
      "Percent Type II errors: 0.17914110429447852\n"
     ]
    }
   ],
   "source": [
    "# We'll make 1000 iterations, use -deep trees, and set our loss function to expontential .\n",
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 4,\n",
    "          'loss': 'exponential',\n",
    "         'subsample':.5}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0, 1.0] / table_train.loc['All', 'All']\n",
    "train_tII_errors = table_train.loc[1.0, 0.0] / table_train.loc['All', 'All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0, 1.0]/table_test.loc['All', 'All']\n",
    "test_tII_errors = table_test.loc[1.0, 0.0]/table_test.loc['All', 'All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: All of these combined really only increased our training set accuracy, but only very very slightly affected our test set accuracy by increasing the number of type I errors, and very slightly decreasing our type II errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
